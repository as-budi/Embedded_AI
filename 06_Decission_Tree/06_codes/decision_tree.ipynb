{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model ID3: 100.00%\n",
      "Prediksi untuk sampel: [6.1 2.8 4.7 1.2] adalah kelas versicolor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Fungsi untuk menghitung entropy\n",
    "def entropy(y):\n",
    "    counts = np.bincount(y)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "# Fungsi untuk membagi dataset berdasarkan split\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "\n",
    "# Fungsi untuk menghitung Information Gain\n",
    "def information_gain(X, y, feature_index, threshold):\n",
    "    parent_entropy = entropy(y)\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "    if len(y_left) == 0 or len(y_right) == 0:\n",
    "        return 0\n",
    "    child_entropy = (len(y_left) / len(y)) * entropy(y_left) + (len(y_right) / len(y)) * entropy(y_right)\n",
    "    return parent_entropy - child_entropy\n",
    "\n",
    "# Fungsi untuk mencari splitting terbaik\n",
    "def best_split(X, y):\n",
    "    best_gain = 0\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    n_features = X.shape[1]\n",
    "    for feature_index in range(n_features):\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            gain = information_gain(X, y, feature_index, threshold)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature_index\n",
    "                best_threshold = threshold\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "# Kelas untuk Decision Tree menggunakan ID3\n",
    "class DecisionTreeID3:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y, depth=0):\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return np.unique(y)[0]\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        feature, threshold = best_split(X, y)\n",
    "        if feature is None:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        X_left, y_left, X_right, y_right = split_dataset(X, y, feature, threshold)\n",
    "        self.tree = {\n",
    "            'feature': feature,\n",
    "            'threshold': threshold,\n",
    "            'left': self.fit(X_left, y_left, depth + 1),\n",
    "            'right': self.fit(X_right, y_right, depth + 1)\n",
    "        }\n",
    "        return self.tree\n",
    "\n",
    "    def predict_one(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "        if x[feature] <= threshold:\n",
    "            return self.predict_one(x, tree['left'])\n",
    "        else:\n",
    "            return self.predict_one(x, tree['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_one(x, self.tree) for x in X])\n",
    "\n",
    "# Memuat dataset Iris dari scikit-learn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target  # Menggunakan fitur numerik secara langsung\n",
    "\n",
    "# Membagi dataset menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat dan melatih model ID3\n",
    "model = DecisionTreeID3()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi dataset uji\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Akurasi Model ID3: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Contoh prediksi satu data\n",
    "sample_data = np.array([X_test[0]])  # Mengambil satu data dari dataset uji\n",
    "predicted_class = model.predict(sample_data)[0]\n",
    "print(f'Prediksi untuk sampel: {sample_data[0]} adalah kelas {iris.target_names[predicted_class]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model C4.5: 100.00%\n",
      "Prediksi untuk sampel: [6.1 2.8 4.7 1.2] adalah kelas versicolor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Fungsi untuk menghitung entropy\n",
    "def entropy(y):\n",
    "    counts = np.bincount(y)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "# Fungsi untuk membagi dataset berdasarkan split\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "\n",
    "# Fungsi untuk menghitung Information Gain\n",
    "def information_gain(X, y, feature_index, threshold):\n",
    "    parent_entropy = entropy(y)\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "    if len(y_left) == 0 or len(y_right) == 0:\n",
    "        return 0\n",
    "    child_entropy = (len(y_left) / len(y)) * entropy(y_left) + (len(y_right) / len(y)) * entropy(y_right)\n",
    "    return parent_entropy - child_entropy\n",
    "\n",
    "# Fungsi untuk menghitung Split Information\n",
    "def split_information(X, feature_index, threshold):\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    left_ratio = np.sum(left_mask) / len(X)\n",
    "    right_ratio = np.sum(right_mask) / len(X)\n",
    "    return - (left_ratio * np.log2(left_ratio) + right_ratio * np.log2(right_ratio)) if left_ratio > 0 and right_ratio > 0 else 1\n",
    "\n",
    "# Fungsi untuk menghitung Gain Ratio\n",
    "def gain_ratio(X, y, feature_index, threshold):\n",
    "    ig = information_gain(X, y, feature_index, threshold)\n",
    "    si = split_information(X, feature_index, threshold)\n",
    "    return ig / si if si != 0 else 0\n",
    "\n",
    "# Fungsi untuk mencari splitting terbaik berdasarkan Gain Ratio\n",
    "def best_split(X, y):\n",
    "    best_gain_ratio = 0\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    n_features = X.shape[1]\n",
    "    for feature_index in range(n_features):\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            gr = gain_ratio(X, y, feature_index, threshold)\n",
    "            if gr > best_gain_ratio:\n",
    "                best_gain_ratio = gr\n",
    "                best_feature = feature_index\n",
    "                best_threshold = threshold\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "# Kelas untuk Decision Tree menggunakan C4.5\n",
    "class DecisionTreeC45:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y, depth=0):\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return np.unique(y)[0]\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        feature, threshold = best_split(X, y)\n",
    "        if feature is None:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        X_left, y_left, X_right, y_right = split_dataset(X, y, feature, threshold)\n",
    "        self.tree = {\n",
    "            'feature': feature,\n",
    "            'threshold': threshold,\n",
    "            'left': self.fit(X_left, y_left, depth + 1),\n",
    "            'right': self.fit(X_right, y_right, depth + 1)\n",
    "        }\n",
    "        return self.tree\n",
    "\n",
    "    def predict_one(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "        if x[feature] <= threshold:\n",
    "            return self.predict_one(x, tree['left'])\n",
    "        else:\n",
    "            return self.predict_one(x, tree['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_one(x, self.tree) for x in X])\n",
    "\n",
    "# Memuat dataset Iris dari scikit-learn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target  # Menggunakan fitur numerik secara langsung\n",
    "\n",
    "# Membagi dataset menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat dan melatih model C4.5\n",
    "model = DecisionTreeC45()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi dataset uji\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Akurasi Model C4.5: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Contoh prediksi satu data\n",
    "sample_data = np.array([X_test[0]])  # Mengambil satu data dari dataset uji\n",
    "predicted_class = model.predict(sample_data)[0]\n",
    "print(f'Prediksi untuk sampel: {sample_data[0]} adalah kelas {iris.target_names[predicted_class]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model CART: 100.00%\n",
      "Prediksi untuk sampel: [6.1 2.8 4.7 1.2] adalah kelas versicolor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Fungsi untuk menghitung Gini Index\n",
    "def gini_index(y):\n",
    "    counts = np.bincount(y)\n",
    "    probabilities = counts / len(y)\n",
    "    return 1 - np.sum([p**2 for p in probabilities if p > 0])\n",
    "\n",
    "# Fungsi untuk membagi dataset berdasarkan split\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "    left_mask = X[:, feature_index] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
    "\n",
    "# Fungsi untuk menghitung Gini Gain\n",
    "def gini_gain(X, y, feature_index, threshold):\n",
    "    parent_gini = gini_index(y)\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n",
    "    if len(y_left) == 0 or len(y_right) == 0:\n",
    "        return 0\n",
    "    child_gini = (len(y_left) / len(y)) * gini_index(y_left) + (len(y_right) / len(y)) * gini_index(y_right)\n",
    "    return parent_gini - child_gini\n",
    "\n",
    "# Fungsi untuk mencari splitting terbaik berdasarkan Gini Gain\n",
    "def best_split(X, y):\n",
    "    best_gini_gain = 0\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    n_features = X.shape[1]\n",
    "    for feature_index in range(n_features):\n",
    "        thresholds = np.unique(X[:, feature_index])\n",
    "        for threshold in thresholds:\n",
    "            gain = gini_gain(X, y, feature_index, threshold)\n",
    "            if gain > best_gini_gain:\n",
    "                best_gini_gain = gain\n",
    "                best_feature = feature_index\n",
    "                best_threshold = threshold\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "# Kelas untuk Decision Tree menggunakan CART\n",
    "class DecisionTreeCART:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y, depth=0):\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return np.unique(y)[0]\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        feature, threshold = best_split(X, y)\n",
    "        if feature is None:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        X_left, y_left, X_right, y_right = split_dataset(X, y, feature, threshold)\n",
    "        self.tree = {\n",
    "            'feature': feature,\n",
    "            'threshold': threshold,\n",
    "            'left': self.fit(X_left, y_left, depth + 1),\n",
    "            'right': self.fit(X_right, y_right, depth + 1)\n",
    "        }\n",
    "        return self.tree\n",
    "\n",
    "    def predict_one(self, x, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "        if x[feature] <= threshold:\n",
    "            return self.predict_one(x, tree['left'])\n",
    "        else:\n",
    "            return self.predict_one(x, tree['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_one(x, self.tree) for x in X])\n",
    "\n",
    "# Memuat dataset Iris dari scikit-learn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target  # Menggunakan fitur numerik secara langsung\n",
    "\n",
    "# Membagi dataset menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membuat dan melatih model CART\n",
    "model = DecisionTreeCART()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Memprediksi dataset uji\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Akurasi Model CART: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Contoh prediksi satu data\n",
    "sample_data = np.array([X_test[0]])  # Mengambil satu data dari dataset uji\n",
    "predicted_class = model.predict(sample_data)[0]\n",
    "print(f'Prediksi untuk sampel: {sample_data[0]} adalah kelas {iris.target_names[predicted_class]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
